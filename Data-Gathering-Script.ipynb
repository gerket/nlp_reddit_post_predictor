{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate file to download posts in the background and save them to the folder so that I can work on the rest of the project while it is happening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did this before we started looking into BeautifulSoup. I don't want to mess with it now. Legacy Code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.11</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pixiedust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Max num of pages to try and get\n",
    "posts=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LFG':pd.DataFrame(), 'nosleep':pd.DataFrame(), \n",
    "jsons = {'talesfromtechsupport':pd.DataFrame(), 'buildapc':pd.DataFrame()}\n",
    "the_headers = {'User-agent': 'project3 Bot 0.4'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'subreddit',\n",
    "    'url',\n",
    "    'author',\n",
    "    'domain',\n",
    "    'downs',\n",
    "    'is_self', \n",
    "    'is_video', \n",
    "    'likes',\n",
    "    'media',\n",
    "    'num_comments',\n",
    "    'num_crossposts',\n",
    "    'num_reports',\n",
    "    'selftext',\n",
    "    'score',\n",
    "    'title',\n",
    "    'ups'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "talesfromtechsupport Iterations:\n",
      "\n",
      "01 02 03 04 05 06 07 08 09 10 \n",
      "11 12 13 14 15 16 17 18 19 20 \n",
      "21 22 23 24 25 26 27 28 29 30 \n",
      "31 32 33 34 35 36 37 38 39 \n",
      "talesfromtechsupport  temp df shape (979, 16)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "buildapc Iterations:\n",
      "\n",
      "01 02 03 04 05 06 07 08 09 10 \n",
      "11 12 13 14 15 16 17 18 19 20 \n",
      "21 22 23 24 25 26 27 28 29 30 \n",
      "31 32 33 34 35 36 37 38 39 \n",
      "buildapc  temp df shape (992, 16)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CPU times: user 2.36 s, sys: 157 ms, total: 2.51 s\n",
      "Wall time: 4min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# The meat of this file.  It goes through and gets posts+1 pages of posts from each subreddit, gets out the relevant features, adds them to a DataFrame and appends to that DataFrame until the loop finishes\n",
    "for k, v in jsons.items():\n",
    "    URL = \"http://www.reddit.com/r/\" + k + \".json\"\n",
    "\n",
    "    res = requests.get(URL, headers = the_headers)\n",
    "    the_json = res.json()\n",
    "\n",
    "    pre_temp_df = pd.DataFrame(the_json['data']['children'])\n",
    "    pre_temp_df = pd.DataFrame(list(pre_temp_df['data']))[features]\n",
    "    jsons[k] = pre_temp_df.copy()\n",
    "    \n",
    "    #print('a', pre_temp_df.shape)\n",
    "    \n",
    "    URL_EXTENDER = \"?after=\"\n",
    "\n",
    "    print(k, 'Iterations:')\n",
    "    for i in range(posts): \n",
    "        last_title = the_json['data']['after']\n",
    "\n",
    "        try:\n",
    "        #retrieve new data\n",
    "            if last_title==None:\n",
    "                break\n",
    "                \n",
    "            temp_data = requests.get(URL+URL_EXTENDER+last_title, headers = the_headers)\n",
    "\n",
    "            the_json = temp_data.json()\n",
    "            \n",
    "            #add to the temp df more\n",
    "        \n",
    "            pre_temp_df = pd.DataFrame(the_json['data']['children'])\n",
    "\n",
    "            if (len(pre_temp_df.columns) == 0):\n",
    "                break\n",
    "            pre_temp_df = pd.DataFrame(list(pre_temp_df['data']))[features]\n",
    "            #print('b', pre_temp_df.shape)\n",
    "\n",
    "            jsons[k] = jsons[k].append(pre_temp_df, ignore_index = True)\n",
    "            \n",
    "            time.sleep(3)\n",
    "            if i % 10 == 0:\n",
    "                print()\n",
    "            print('%02d' % (i+1), end=\" \")\n",
    "\n",
    "        except _ as e:\n",
    "            print()\n",
    "            print(e, \"Let's see what we've got!\")\n",
    "            break\n",
    "    \n",
    "    #add temp df to main df\n",
    "    print()\n",
    "    print(k,' temp df shape', jsons[k].shape)\n",
    "    print('\\n\\n\\n')\n",
    "    \n",
    "#print(jsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(last_title==None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(979, 16)\n",
      "(992, 16)\n"
     ]
    }
   ],
   "source": [
    "for k, v in jsons.items():\n",
    "    print(v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1971, 16)\n"
     ]
    }
   ],
   "source": [
    "main_df = pd.DataFrame()\n",
    "for k, v in jsons.items():\n",
    "    main_df = main_df.append(v.copy(), ignore_index = True)\n",
    "main_df.drop_duplicates(inplace = True, subset=['url'])\n",
    "print(main_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "path = './data/new_data.csv'\n",
    "main_df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the csv\n",
    "path = './data/new_data.csv'\n",
    "test_db = pd.read_csv(path)\n",
    "print(test_db.shape)\n",
    "test_db.equals(main_df) #returns false because the Nones are now NaNs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
