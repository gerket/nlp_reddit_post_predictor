{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate file to download posts in the background and save them to the folder so that I can work on the rest of the project while it is happening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did this before we started looking into BeautifulSoup. I don't want to mess with it now. Legacy Code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.11</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time, requests\n",
    "import pandas as pd\n",
    "import pixiedust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Max num of pages to try and get\n",
    "posts=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jsons = {'talesfromtechsupport':pd.DataFrame(), 'LFG':pd.DataFrame(), 'nosleep':pd.DataFrame()}\n",
    "the_headers = {'User-agent': 'project3 Bot 0.4'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'subreddit',\n",
    "    'url',\n",
    "    'author',\n",
    "    'domain',\n",
    "    'downs',\n",
    "    'is_self', \n",
    "    'is_video', \n",
    "    'likes',\n",
    "    'media',\n",
    "    'num_comments',\n",
    "    'num_crossposts',\n",
    "    'num_reports',\n",
    "    'selftext',\n",
    "    'score',\n",
    "    'title',\n",
    "    'ups'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "talesfromtechsupport Iterations:\n",
      "\n",
      "01 02 03 04 05 06 07 08 09 10 \n",
      "11 12 13 14 15 16 17 18 19 20 \n",
      "21 22 23 24 25 26 27 28 29 30 \n",
      "31 32 33 34 35 36 37 38 39 \n",
      "talesfromtechsupport  temp df shape (978, 16)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LFG Iterations:\n",
      "\n",
      "01 02 03 04 05 06 07 08 09 10 \n",
      "11 12 13 14 15 16 17 18 19 20 \n",
      "21 22 23 24 25 26 27 28 29 30 \n",
      "31 32 33 34 35 36 \n",
      "LFG  temp df shape (921, 16)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nosleep Iterations:\n",
      "\n",
      "01 02 03 04 05 06 07 08 09 10 \n",
      "11 12 13 14 15 16 17 18 19 20 \n",
      "21 22 23 24 25 26 27 28 29 30 \n",
      "31 32 \n",
      "nosleep  temp df shape (816, 16)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CPU times: user 3.83 s, sys: 309 ms, total: 4.14 s\n",
      "Wall time: 5min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# The meat of this file.  It goes through and gets posts+1 pages of posts from each subreddit, gets out the relevant features, adds them to a DataFrame and appends to that DataFrame until the loop finishes\n",
    "for k, v in jsons.items():\n",
    "    URL = \"http://www.reddit.com/r/\" + k + \".json\"\n",
    "\n",
    "    res = requests.get(URL, headers = the_headers)\n",
    "    the_json = res.json()\n",
    "\n",
    "    pre_temp_df = pd.DataFrame(the_json['data']['children'])\n",
    "    pre_temp_df = pd.DataFrame(list(pre_temp_df['data']))[features]\n",
    "    jsons[k] = pre_temp_df.copy()\n",
    "    \n",
    "    #print('a', pre_temp_df.shape)\n",
    "    \n",
    "    URL_EXTENDER = \"?after=\"\n",
    "\n",
    "    print(k, 'Iterations:')\n",
    "    for i in range(posts): \n",
    "        last_title = the_json['data']['after']\n",
    "\n",
    "        try:\n",
    "        #retrieve new data\n",
    "            if last_title==None:\n",
    "                break\n",
    "                \n",
    "            temp_data = requests.get(URL+URL_EXTENDER+last_title, headers = the_headers)\n",
    "\n",
    "            the_json = temp_data.json()\n",
    "            \n",
    "            #add to the temp df more\n",
    "        \n",
    "            pre_temp_df = pd.DataFrame(the_json['data']['children'])\n",
    "\n",
    "            if (len(pre_temp_df.columns) == 0):\n",
    "                break\n",
    "            pre_temp_df = pd.DataFrame(list(pre_temp_df['data']))[features]\n",
    "            #print('b', pre_temp_df.shape)\n",
    "\n",
    "            jsons[k] = jsons[k].append(pre_temp_df, ignore_index = True)\n",
    "            \n",
    "            time.sleep(3)\n",
    "            if i % 10 == 0:\n",
    "                print()\n",
    "            print('%02d' % (i+1), end=\" \")\n",
    "\n",
    "        except _ as e:\n",
    "            print()\n",
    "            print(e, \"Let's see what we've got!\")\n",
    "            break\n",
    "    \n",
    "    #add temp df to main df\n",
    "    print()\n",
    "    print(k,' temp df shape', jsons[k].shape)\n",
    "    print('\\n\\n\\n')\n",
    "    \n",
    "#print(jsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(last_title==None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(978, 16)\n",
      "(921, 16)\n",
      "(816, 16)\n"
     ]
    }
   ],
   "source": [
    "for k, v in jsons.items():\n",
    "    print(v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2715, 16)\n"
     ]
    }
   ],
   "source": [
    "main_df = pd.DataFrame()\n",
    "for k, v in jsons.items():\n",
    "    main_df = main_df.append(v.copy(), ignore_index = True)\n",
    "main_df.drop_duplicates(inplace = True, subset=['url'])\n",
    "print(main_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>domain</th>\n",
       "      <th>downs</th>\n",
       "      <th>is_self</th>\n",
       "      <th>is_video</th>\n",
       "      <th>likes</th>\n",
       "      <th>media</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>num_crossposts</th>\n",
       "      <th>num_reports</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>ups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>talesfromtechsupport</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>MagicBigfoot</td>\n",
       "      <td>self.talesfromtechsupport</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Hey, we can have two stickies now!\\n\\n---\\n\\nS...</td>\n",
       "      <td>1952</td>\n",
       "      <td>TFTS POSTING RULES (MOBILE USERS PLEASE READ!)</td>\n",
       "      <td>1952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talesfromtechsupport</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>TheTableClothe</td>\n",
       "      <td>self.talesfromtechsupport</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>I did tech support for a large broadband compa...</td>\n",
       "      <td>509</td>\n",
       "      <td>My WiFi isnâ€™t working!</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>talesfromtechsupport</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>miscreancy</td>\n",
       "      <td>self.talesfromtechsupport</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Another tale from my days working for $GiantSu...</td>\n",
       "      <td>1625</td>\n",
       "      <td>\"It could be worse, this could be a company ma...</td>\n",
       "      <td>1625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>talesfromtechsupport</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>I_Have_A_Chode</td>\n",
       "      <td>self.talesfromtechsupport</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>So this happened friday morning. \\n\\n$chode = ...</td>\n",
       "      <td>200</td>\n",
       "      <td>The mysterious missed phone calls!</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>talesfromtechsupport</td>\n",
       "      <td>https://www.reddit.com/r/talesfromtechsupport/...</td>\n",
       "      <td>kayakmainac</td>\n",
       "      <td>self.talesfromtechsupport</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>LTL/FTP\\n\\nSo I work in IT services for a univ...</td>\n",
       "      <td>493</td>\n",
       "      <td>A UPS test! During peak time? The day before a...</td>\n",
       "      <td>493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              subreddit                                                url  \\\n",
       "0  talesfromtechsupport  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "1  talesfromtechsupport  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "2  talesfromtechsupport  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "3  talesfromtechsupport  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "4  talesfromtechsupport  https://www.reddit.com/r/talesfromtechsupport/...   \n",
       "\n",
       "           author                     domain  downs  is_self  is_video likes  \\\n",
       "0    MagicBigfoot  self.talesfromtechsupport      0     True     False  None   \n",
       "1  TheTableClothe  self.talesfromtechsupport      0     True     False  None   \n",
       "2      miscreancy  self.talesfromtechsupport      0     True     False  None   \n",
       "3  I_Have_A_Chode  self.talesfromtechsupport      0     True     False  None   \n",
       "4     kayakmainac  self.talesfromtechsupport      0     True     False  None   \n",
       "\n",
       "  media  num_comments  num_crossposts num_reports  \\\n",
       "0  None            77               0        None   \n",
       "1  None            56               0        None   \n",
       "2  None           155               0        None   \n",
       "3  None             4               0        None   \n",
       "4  None            56               0        None   \n",
       "\n",
       "                                            selftext  score  \\\n",
       "0  Hey, we can have two stickies now!\\n\\n---\\n\\nS...   1952   \n",
       "1  I did tech support for a large broadband compa...    509   \n",
       "2  Another tale from my days working for $GiantSu...   1625   \n",
       "3  So this happened friday morning. \\n\\n$chode = ...    200   \n",
       "4  LTL/FTP\\n\\nSo I work in IT services for a univ...    493   \n",
       "\n",
       "                                               title   ups  \n",
       "0     TFTS POSTING RULES (MOBILE USERS PLEASE READ!)  1952  \n",
       "1                             My WiFi isnâ€™t working!   509  \n",
       "2  \"It could be worse, this could be a company ma...  1625  \n",
       "3                 The mysterious missed phone calls!   200  \n",
       "4  A UPS test! During peak time? The day before a...   493  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to csv\n",
    "path = './data/new_data.csv'\n",
    "main_df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the csv\n",
    "path = './data/new_data.csv'\n",
    "test_db = pd.read_csv(path)\n",
    "print(test_db.shape)\n",
    "test_db.equals(main_df) #returns false because the Nones are now NaNs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
